{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `smlb` mini demonstration:<br>The watercolor pigments 2019 dataset\n",
    "\n",
    "Scientific Machine Learning Benchmark:<br>\n",
    "A benchmark of regression models in chem- and materials informatics.<br>\n",
    "2019-2020, Citrine Informatics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import smlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset, which comes with a featurizer. Use tab completion to find the right import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smlb.datasets.experimental.watercolor_pigments_c19.watercolor_pigments_c19 import \\\n",
    "    WatercolorPigments2019Dataset, WatercolorPigments2019DatasetFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use standard learners from `scikit-learn` and a simple learning curve workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smlb.learners.scikit_learn.gaussian_process_regression_sklearn import GaussianProcessRegressionSklearn\n",
    "from smlb.learners.scikit_learn.random_forest_regression_sklearn import RandomForestRegressionSklearn\n",
    "from smlb.learners.scikit_learn.extremely_randomized_trees_regression_sklearn import ExtremelyRandomizedTreesRegressionSklearn\n",
    "\n",
    "from smlb.workflows.learning_curve_regression import LearningCurveRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information about the dataset.\n",
    "Note that references are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WatercolorPigments2019Dataset.__doc__) # using `print` instead of `help` avoids clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 primary pigments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_names = WatercolorPigments2019Dataset.COLOR_NAMES[1:]  # indexing starts with 1, as in the original reference\n",
    "print(pd.DataFrame(color_names, index=range(1,13+1), columns=['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since watercolors are semi-transparent, the color of these pigments depends on their amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a table mapping index and concentration to color\n",
    "dataset = WatercolorPigments2019Dataset(filter_=\"primary\")  # only primary pigments\n",
    "color_table = dict()\n",
    "for entry, rgb in zip(dataset.samples(), dataset.labels()):\n",
    "    color_table[entry['index'], entry['concentration']] = rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "(fig,ax) = plt.subplots(figsize=(14,8))\n",
    "concentrations = np.unique(tuple(key[1] for key in color_table.keys()))\n",
    "rect_xsize, rect_ysize, pad_x, pad_y = 10, 10, 2, 2\n",
    "ax.set_xlim(-rect_xsize, len(concentrations)*(rect_xsize+pad_x)+pad_x)\n",
    "ax.set_ylim(rect_ysize, -13*(rect_ysize+pad_y)-pad_y)\n",
    "ax.text(-rect_xsize/2, rect_ysize/2, 'Color', ha='center', weight='bold')\n",
    "for j, c in enumerate(concentrations):\n",
    "    ax.text(j*(rect_xsize+pad_x)+rect_xsize/2, rect_ysize/2, f'{c} mL', ha='center', weight='bold')\n",
    "for i in range(1, 13+1):\n",
    "    ax.text(-rect_xsize/2, -i*(rect_ysize+pad_y)+rect_ysize/2, str(i), weight='bold')\n",
    "    for j, c in enumerate(concentrations):\n",
    "        ax.add_patch(mpl.patches.Rectangle((j*(rect_xsize+pad_x), -i*(rect_ysize+pad_y)), rect_xsize, rect_ysize, color=color_table[i,c] / 255, fill=True))\n",
    "ax.invert_yaxis()\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping from concentration to color channel is non-linear:\n",
    "\n",
    "Note that below plot uses a single color for each line; while it is\n",
    "possible to draw line gradients via `matplotlib.collections.LineCollection`,\n",
    "the visual effect is rather limited and hard to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,12))\n",
    "concentrations = (0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.16)\n",
    "\n",
    "for index in range(1, 13+1):\n",
    "    colors = np.asarray([color_table[index, c] for c in concentrations])\n",
    "    ax[0].plot(concentrations, colors[:,0], color=colors[0]/255)\n",
    "    ax[1].plot(concentrations, colors[:,1], color=colors[0]/255)\n",
    "    ax[2].plot(concentrations, colors[:,2], color=colors[0]/255, label=index)\n",
    "\n",
    "ax[0].set_xlabel('concentration / mL'); ax[0].set_ylabel('red')\n",
    "ax[1].set_xlabel('concentration / mL'); ax[1].set_ylabel('green')\n",
    "ax[2].set_xlabel('concentration / mL'); ax[2].set_ylabel('blue')\n",
    "\n",
    "ax[2].legend(loc=(1.05, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: only mixtures, one-hot encoding, random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default initializer parameters of the water colors dataset yield only mixtures (no primary pigments) via a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WatercolorPigments2019Dataset(labelf=lambda arg: arg[0])\n",
    "features = WatercolorPigments2019DatasetFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 15% of data for validation.\n",
    "Training set sizes are equi-distant in log-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = dataset.num_samples, round(dataset.num_samples * 0.15)\n",
    "validation = smlb.RandomSubsetSampler(size=m, rng=0)\n",
    "\n",
    "training_sizes = np.asarray( np.logspace(1, np.log10(n-m), num=6), dtype=int )\n",
    "print(training_sizes)\n",
    "training = tuple(smlb.RandomSubsetSampler(size=n, rng=0) for n in training_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "kernel = skl.gaussian_process.kernels.DotProduct() + skl.gaussian_process.kernels.WhiteKernel()\n",
    "kernel = skl.gaussian_process.kernels.RBF(length_scale=1, length_scale_bounds='fixed') + skl.gaussian_process.kernels.WhiteKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_gpr_skl = GaussianProcessRegressionSklearn(kernel=kernel, random_state=0) # default is Gaussian kernel\n",
    "learner_rf_skl = RandomForestRegressionSklearn(random_state=0)\n",
    "learner_ert_skl = ExtremelyRandomizedTreesRegressionSklearn(random_state=0, uncertainties='naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "learning_curve = smlb.LearningCurvePlot(target=ax, axes_labels=(\"training set size\", \"root mean-squared error\"))\n",
    "workflow = LearningCurveRegression(data=dataset, features=features, training=training, validation=validation, \n",
    "                                   learners=[learner_rf_skl, learner_ert_skl, learner_gpr_skl], evaluations=[learning_curve])\n",
    "workflow.run()\n",
    "ax.legend([\"Random forest\", \"Extremely randomized trees\", \"Gaussian process\"], loc=(1.05, 0.05));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian process fails with constant predictions, resulting in a flat learning curve at high error.\n",
    "\n",
    "This seems to be a problem of hyperparameter optimization: When trained with a Gaussian kernel and \n",
    "additive Gaussian noise with fixed hyperparameters (length scale 0.05, noise level 0.1), performance\n",
    "is much better, albeit still worse than random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smlb",
   "language": "python",
   "name": "smlb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
